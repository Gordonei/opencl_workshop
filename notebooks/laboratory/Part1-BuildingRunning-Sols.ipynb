{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Programming Fancy Devices (with OpenCL) Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = int(1e8)\n",
    "a = numpy.random.rand(N).astype(numpy.float32)\n",
    "b = numpy.random.rand(N).astype(numpy.float32)\n",
    "c = numpy.empty_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program_source = \"\"\"\n",
    "kernel void sum(global float *a, \n",
    "                global float *b, \n",
    "                global float *c)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  c[gid] = a[gid] + b[gid];\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NVIDIA Platform, Device, Context, Queue\n",
    "nvidia_platform = pyopencl.get_platforms()[0]\n",
    "nvidia_devices = nvidia_platform.get_devices()\n",
    "nvidia_context = pyopencl.Context(devices=nvidia_devices)\n",
    "nvidia_queue = pyopencl.CommandQueue(nvidia_context)\n",
    "\n",
    "#NVIDIA Compiling\n",
    "nvidia_program_source = pyopencl.Program(nvidia_context,program_source)\n",
    "nvidia_program = nvidia_program_source.build()\n",
    "    \n",
    "#NVIDIA Buffers\n",
    "a_nvidia_buffer = pyopencl.Buffer(nvidia_context,\n",
    "                                    flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                    size=a.nbytes)\n",
    "b_nvidia_buffer = pyopencl.Buffer(nvidia_context, \n",
    "                                    flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                    size=b.nbytes)\n",
    "c_nvidia_buffer = pyopencl.Buffer(nvidia_context, \n",
    "                                    flags=pyopencl.mem_flags.WRITE_ONLY, \n",
    "                                    size=c.nbytes)\n",
    "\n",
    "def run_gpu_program(): \n",
    "    #copying data onto GPU\n",
    "    pyopencl.enqueue_copy(nvidia_queue,\n",
    "                          src=a,\n",
    "                          dest=a_nvidia_buffer)\n",
    "    pyopencl.enqueue_copy(nvidia_queue,\n",
    "                          src=b,\n",
    "                          dest=b_nvidia_buffer)\n",
    "    \n",
    "    #running program\n",
    "    kernel_arguments = (a_nvidia_buffer,b_nvidia_buffer,c_nvidia_buffer) \n",
    "    nvidia_program.sum(nvidia_queue,\n",
    "                       a.shape, #global size\n",
    "                       None, #local size\n",
    "                       *kernel_arguments)\n",
    "\n",
    "    #copying data off GPU\n",
    "    copy_off_event = pyopencl.enqueue_copy(nvidia_queue,\n",
    "                                           src=c_nvidia_buffer,\n",
    "                                           dest=c)\n",
    "    copy_off_event.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the vector addition example, as above, but using the Intel platform to program the instance's CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Building the Intel\n",
    "intel_platform = pyopencl.get_platforms()[1]\n",
    "intel_devices = intel_platform.get_devices()\n",
    "intel_context = pyopencl.Context(devices=intel_devices)\n",
    "\n",
    "#Building the program\n",
    "intel_program_source = pyopencl.Program(intel_context,program_source)\n",
    "intel_program = intel_program_source.build()\n",
    "\n",
    "#Memory buffers\n",
    "a_intel_buffer = pyopencl.Buffer(intel_context,\n",
    "                                 flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                 size=a.nbytes)\n",
    "b_intel_buffer = pyopencl.Buffer(intel_context, \n",
    "                                 flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                 size=b.nbytes)\n",
    "c_intel_buffer = pyopencl.Buffer(intel_context, \n",
    "                                 flags=pyopencl.mem_flags.WRITE_ONLY, \n",
    "                                 size=c.nbytes)\n",
    "#Command Queue\n",
    "intel_queue = pyopencl.CommandQueue(intel_context)\n",
    "\n",
    "def run_cpu_program():\n",
    "    #copying data onto CPU\n",
    "    pyopencl.enqueue_copy(intel_queue,\n",
    "                          src=a,\n",
    "                          dest=a_intel_buffer)\n",
    "    pyopencl.enqueue_copy(intel_queue,\n",
    "                          src=b,\n",
    "                          dest=b_intel_buffer)\n",
    "    \n",
    "    #running program\n",
    "    kernel_arguments = (a_intel_buffer,b_intel_buffer,c_intel_buffer) \n",
    "    intel_program.sum(intel_queue,\n",
    "                       a.shape, #global size\n",
    "                       None, #local size\n",
    "                       *kernel_arguments)\n",
    "\n",
    "    #copying data off CPU\n",
    "    copy_off_event = pyopencl.enqueue_copy(intel_queue,\n",
    "                                           src=c_intel_buffer,\n",
    "                                           dest=c)\n",
    "    copy_off_event.wait()\n",
    "\n",
    "#checking result\n",
    "run_cpu_program()\n",
    "if((c - (a + b)).sum() > 0.0): print(\"result does not match\")\n",
    "else: print(\"result matches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the two using the `%timeit` magic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit run_gpu_program()\n",
    "%timeit run_cpu_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
