{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Programming Fancy Devices (with OpenCL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything else, we need to import [PyOpenCL](https://documen.tician.de/pyopencl/) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the NVIDIA platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Look at the platforms available\n",
    "2. Select the first one, NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pyopencl.get_platforms())\n",
    "nvidia_platform = pyopencl.get_platforms()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting the devices from the platform\n",
    "2. Using the devices to create the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvidia_devices = nvidia_platform.get_devices()\n",
    "nvidia_context = pyopencl.Context(devices=nvidia_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling a program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Specify the program source for a simple vector operation: $\\vec{c} = \\vec{a} + \\vec{b}$\n",
    "2. Create the program object\n",
    "3. Build the program\n",
    "4. Get the list of all the available kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_source = \"\"\"\n",
    "kernel void sum(global float *a, \n",
    "                global float *b, \n",
    "                global float *c)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  c[gid] = a[gid] + b[gid];\n",
    "}\n",
    "\"\"\"\n",
    "nvidia_program_source = pyopencl.Program(nvidia_context,program_source)\n",
    "nvidia_program = nvidia_program_source.build()\n",
    "print(\"Kernel Names:\",nvidia_program.get_info(pyopencl.program_info.KERNEL_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the command queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the queue using the existing context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvidia_queue = pyopencl.CommandQueue(nvidia_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating memory resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this will be explained in more detail in part II)\n",
    "1. Create the arrays with data in them\n",
    "2. Create the OpenCL buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = int(1e8)\n",
    "a = numpy.random.rand(N).astype(numpy.float32)\n",
    "b = numpy.random.rand(N).astype(numpy.float32)\n",
    "c = numpy.empty_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_nvidia_buffer = pyopencl.Buffer(nvidia_context,\n",
    "                                  flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                  size=a.nbytes)\n",
    "b_nvidia_buffer = pyopencl.Buffer(nvidia_context, \n",
    "                                  flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                  size=b.nbytes)\n",
    "c_nvidia_buffer = pyopencl.Buffer(nvidia_context, \n",
    "                                  flags=pyopencl.mem_flags.WRITE_ONLY, \n",
    "                                  size=c.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy the data from the arrays to the read buffers\n",
    "2. Run the program\n",
    "3. Ready the data from the result buffer, and wait for the read to finish\n",
    "4. Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_gpu_program():\n",
    "    #copying data onto GPU\n",
    "    pyopencl.enqueue_copy(nvidia_queue,\n",
    "                          src=a,\n",
    "                          dest=a_nvidia_buffer)\n",
    "    pyopencl.enqueue_copy(nvidia_queue,\n",
    "                          src=b,\n",
    "                          dest=b_nvidia_buffer)\n",
    "    \n",
    "    #running program\n",
    "    kernel_arguments = (a_nvidia_buffer,b_nvidia_buffer,c_nvidia_buffer) \n",
    "    nvidia_program.sum(nvidia_queue,\n",
    "                       a.shape, #global size\n",
    "                       None, #local size\n",
    "                       *kernel_arguments)\n",
    "\n",
    "    #copying data off GPU\n",
    "    copy_off_event = pyopencl.enqueue_copy(nvidia_queue,\n",
    "                                           src=c_nvidia_buffer,\n",
    "                                           dest=c)\n",
    "    copy_off_event.wait()\n",
    "    \n",
    "def check_results(a,b,c):\n",
    "    if((c - (a + b)).sum() > 0.0): print(\"result does not match\")\n",
    "    else: print(\"result matches!\")    \n",
    "\n",
    "#checking result\n",
    "run_gpu_program()\n",
    "check_results(a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the vector addition example, as above, but using the Intel platform to program the instance's CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Building the Intel\n",
    "intel_platform = pyopencl.get_platforms()[1]\n",
    "intel_devices = intel_platform.get_devices()\n",
    "intel_context = pyopencl.Context(devices=intel_devices)\n",
    "\n",
    "#Building the program\n",
    "intel_program_source = pyopencl.Program(intel_context,program_source)\n",
    "intel_program = intel_program_source.build()\n",
    "\n",
    "#Memory buffers\n",
    "a_intel_buffer = pyopencl.Buffer(intel_context,\n",
    "                                 flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                 size=a.nbytes)\n",
    "b_intel_buffer = pyopencl.Buffer(intel_context, \n",
    "                                 flags=pyopencl.mem_flags.READ_ONLY, \n",
    "                                 size=b.nbytes)\n",
    "c_intel_buffer = pyopencl.Buffer(intel_context, \n",
    "                                 flags=pyopencl.mem_flags.WRITE_ONLY, \n",
    "                                 size=c.nbytes)\n",
    "#Command Queue\n",
    "intel_queue = pyopencl.CommandQueue(intel_context)\n",
    "\n",
    "def run_cpu_program():\n",
    "    #copying data onto CPU\n",
    "    pyopencl.enqueue_copy(intel_queue,\n",
    "                          src=a,\n",
    "                          dest=a_intel_buffer)\n",
    "    pyopencl.enqueue_copy(intel_queue,\n",
    "                          src=b,\n",
    "                          dest=b_intel_buffer)\n",
    "    \n",
    "    #running program\n",
    "    kernel_arguments = (a_intel_buffer,b_intel_buffer,c_intel_buffer) \n",
    "    intel_program.sum(intel_queue,\n",
    "                       a.shape, #global size\n",
    "                       None, #local size\n",
    "                       *kernel_arguments)\n",
    "\n",
    "    #copying data off CPU\n",
    "    copy_off_event = pyopencl.enqueue_copy(intel_queue,\n",
    "                                           src=c_intel_buffer,\n",
    "                                           dest=c)\n",
    "    copy_off_event.wait()\n",
    "\n",
    "#checking result\n",
    "run_cpu_program()\n",
    "if((c - (a + b)).sum() > 0.0): print(\"result does not match\")\n",
    "else: print(\"result matches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the two using the `%timeit` magic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit run_gpu_program()\n",
    "%timeit run_cpu_program()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
