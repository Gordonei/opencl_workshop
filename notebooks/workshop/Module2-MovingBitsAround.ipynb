{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Module 2 - Moving Bits Around (with OpenCL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Library Import\n",
    "Before doing anything else, we need to import [PyOpenCL](https://documen.tician.de/pyopencl/) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl,numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up platforms, devices and context\n",
    "We're going to setup the devices and context as explicit objects because we might want to interogate their runtime information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "platforms = pyopencl.get_platforms()\n",
    "nvidia_device,intel_device = [platform.get_devices()[0] \n",
    "                              for platform in platforms]\n",
    "nvidia_context,intel_context = [pyopencl.Context(devices=[device]) \n",
    "                                for device in (nvidia_device,intel_device)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Communicating between Host and Device\n",
    "### Setting up the program\n",
    "1. Create a program for Vector element-wise multiplication\n",
    "2. Compile the programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_source = \"\"\"\n",
    "kernel void square(global long *b)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  \n",
    "  b[gid] = b[gid]*b[gid];\n",
    "}\n",
    "\n",
    "kernel void operation(global long *a,\n",
    "                      global long *b)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  \n",
    "  long a_temp = a[gid];\n",
    "  long b_temp = b[gid];\n",
    "  \n",
    "  b[gid] = b_temp/a_temp + b_temp*a_temp - b_temp%a_temp;\n",
    "}\n",
    "\"\"\"\n",
    "nvidia_program_source,intel_program_source = [pyopencl.Program(context,program_source) \n",
    "                                              for context in (nvidia_context,intel_context)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvidia_program,intel_program = [program.build()\n",
    "                                for program \n",
    "                                in (nvidia_program_source,\n",
    "                                    intel_program_source)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the global memory resource\n",
    "1. Defining source data parameters\n",
    "2. Creating the source data\n",
    "3. Creating the memory resources within the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 100\n",
    "N = int(64e2)\n",
    "dt = numpy.int64\n",
    "dt_size = numpy.dtype(dt).itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = numpy.random.randint(low=1,high=10,size=(M,N)).astype(dt)\n",
    "b = numpy.random.randint(low=1,high=1000,size=(M,N)).astype(dt)*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_buffers(context,a_size,b_size):\n",
    "    mem_flags = pyopencl.mem_flags.READ_ONLY | pyopencl.mem_flags.ALLOC_HOST_PTR\n",
    "    a_buffer = pyopencl.Buffer(context,\n",
    "                               flags = mem_flags, \n",
    "                               size = a_size)\n",
    "    b_buffer = pyopencl.Buffer(context, \n",
    "                               flags = mem_flags,                               \n",
    "                               size = b_size)\n",
    "    return a_buffer,b_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvidia_a_buffer,nvidia_b_buffer = create_buffers(nvidia_context,\n",
    "                                                 N*dt_size,\n",
    "                                                 N*dt_size)\n",
    "intel_a_buffer,intel_b_buffer = create_buffers(intel_context,\n",
    "                                               N*dt_size,\n",
    "                                               N*dt_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the program\n",
    "### Defining the host program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_norm(queue,a,a_buffer,b,b_buffer,program):\n",
    "    c = numpy.empty_like(a)\n",
    "    total = 0.0\n",
    "    i = 0\n",
    "    for i in range(M):\n",
    "        a_row = a[i]\n",
    "        b_row = b[i]\n",
    "        #for i,(a_row,b_row) in enumerate(zip(a,b)):\n",
    "        #copying data onto device\n",
    "        copyon_events = [pyopencl.enqueue_copy(queue,\n",
    "                                                src=a_row,\n",
    "                                                dest=a_buffer,\n",
    "                                                is_blocking = False),\n",
    "                         pyopencl.enqueue_copy(queue,\n",
    "                                                src=b_row,\n",
    "                                                dest=b_buffer,\n",
    "                                                is_blocking = False)]\n",
    "        \n",
    "        #running program\n",
    "        kernel_event = program.operation(queue,\n",
    "                                         a_row.shape, #global size\n",
    "                                         None, #local size\n",
    "                                         a_buffer,b_buffer,\n",
    "                                         wait_for = copyon_events)\n",
    "        \n",
    "        kernel_event2 = program.square(queue,\n",
    "                                       b_row.shape, #global size\n",
    "                                       None, #local size\n",
    "                                       b_buffer,\n",
    "                                       wait_for = [kernel_event])\n",
    "        \n",
    "        #copying data off device\n",
    "        copyoff_event = pyopencl.enqueue_copy(queue,\n",
    "                                              src = b_buffer,\n",
    "                                              dest = c[i],\n",
    "                                              wait_for = [kernel_event2],\n",
    "                                              is_blocking = False)\n",
    "            \n",
    "        #wait for copy-off to finish\n",
    "        copyoff_event.wait()\n",
    "        i += 1\n",
    "        \n",
    "    total = c.sum()\n",
    "        \n",
    "    return total**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-order Execution\n",
    "1. In-order queue\n",
    "2. Computing the norm\n",
    "3. Checking the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvidia_io_queue = pyopencl.CommandQueue(nvidia_context)\n",
    "intel_io_queue = pyopencl.CommandQueue(intel_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvidia_io_norm = compute_norm(nvidia_io_queue,\n",
    "                              a,nvidia_a_buffer,\n",
    "                              b,nvidia_b_buffer,\n",
    "                              nvidia_program)\n",
    "\n",
    "intel_io_norm = compute_norm(intel_io_queue,\n",
    "                              a,intel_a_buffer,\n",
    "                              b,intel_b_buffer,\n",
    "                              intel_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reference_result = numpy.linalg.norm(b/a + b*a - b%a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(reference_result - nvidia_io_norm > 0): raise Exception(\"nvidia result does not match!\")\n",
    "if(reference_result - intel_io_norm > 0): raise Exception(\"intel result does not match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-order Execution\n",
    "Similiar to before, but using out of order execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvidia_oo_queue = pyopencl.CommandQueue(nvidia_context,\n",
    "                                        properties = pyopencl.command_queue_properties.OUT_OF_ORDER_EXEC_MODE_ENABLE)\n",
    "intel_oo_queue = pyopencl.CommandQueue(intel_context,\n",
    "                                       properties = pyopencl.command_queue_properties.OUT_OF_ORDER_EXEC_MODE_ENABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvidia_oo_norm = compute_norm(nvidia_oo_queue,\n",
    "                              a,nvidia_a_buffer,\n",
    "                              b,nvidia_b_buffer,\n",
    "                              nvidia_program)\n",
    "    \n",
    "intel_oo_norm = compute_norm(intel_oo_queue,\n",
    "                             a,intel_a_buffer,\n",
    "                             b,intel_b_buffer,\n",
    "                             intel_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(reference_result - nvidia_oo_norm > 0): raise Exception(\"nvidia result does not match!\")\n",
    "if(reference_result - intel_oo_norm > 0): raise Exception(\"intel result does not match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%timeit -n 1 compute_norm(nvidia_io_queue,a,nvidia_a_buffer,b,nvidia_b_buffer,nvidia_program)\n",
    "%timeit -n 1 compute_norm(intel_io_queue,a,intel_a_buffer,b,intel_b_buffer,intel_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n 1 compute_norm(nvidia_oo_queue,a,nvidia_a_buffer,b,nvidia_b_buffer,nvidia_program)\n",
    "%timeit -n 1 compute_norm(intel_oo_queue,a,intel_a_buffer,b,intel_b_buffer,intel_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n 1 numpy.linalg.norm(b/a + b*a - b%a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helping the device talk to itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the program\n",
    "1. Compiling the new program\n",
    "2. Rewriting the calling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_source_local = \"\"\"\n",
    "#define WG_SIZE 128\n",
    "kernel void operation_local(global long *a,\n",
    "                            global long *b,\n",
    "                             local long *c)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  int lid = get_local_id(0);\n",
    "  \n",
    "  long a_temp = a[gid];\n",
    "  long b_temp = b[gid];\n",
    "  \n",
    "  long result = b_temp/a_temp + b_temp*a_temp - b_temp%a_temp;\n",
    "  c[lid] = result * result;\n",
    "  \n",
    "  barrier(CLK_LOCAL_MEM_FENCE);\n",
    "  \n",
    "  long sum = 0;\n",
    "  if(lid==0){\n",
    "      int wgid = get_group_id(0);\n",
    "      for(int i=0;i<WG_SIZE;++i) sum += c[i];\n",
    "      b[wgid] = sum;\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "nvidia_program_source,intel_program_source = [pyopencl.Program(context,program_source_local) \n",
    "                                              for context in (nvidia_context,intel_context)]\n",
    "nvidia_program_local,intel_program_local = [program.build()\n",
    "                                            for program \n",
    "                                            in (nvidia_program_source,intel_program_source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_norm_local(queue,a,a_buffer,b,b_buffer,program):\n",
    "    WG_SIZE = 128\n",
    "    wgs = int(len(a[0])/WG_SIZE)\n",
    "    \n",
    "    c = numpy.empty((len(a),wgs),dtype=dt)\n",
    "    total = 0.0\n",
    "    for i,(a_row,b_row) in enumerate(zip(a,b)):\n",
    "        #copying data onto device\n",
    "        copyon_events = []\n",
    "        \n",
    "        copyon_events += [pyopencl.enqueue_copy(queue,\n",
    "                                                src=a_row,\n",
    "                                                dest=a_buffer,\n",
    "                                                is_blocking = False)]\n",
    "        copyon_events += [pyopencl.enqueue_copy(queue,\n",
    "                                                src=b_row,\n",
    "                                                dest=b_buffer,\n",
    "                                                is_blocking = False)]\n",
    "        \n",
    "        #running program\n",
    "        local_c = pyopencl.LocalMemory(WG_SIZE*dt_size)\n",
    "        kernel_event = program.operation_local(queue,\n",
    "                                               a_row.shape, #global size\n",
    "                                               (WG_SIZE,), #local size\n",
    "                                               a_buffer,b_buffer,local_c,\n",
    "                                               wait_for = copyon_events)\n",
    "        \n",
    "        \n",
    "        #copying data off device\n",
    "        copyoff_event = pyopencl.enqueue_copy(queue,\n",
    "                                              src = b_buffer,\n",
    "                                              dest = c[i],\n",
    "                                              wait_for = [kernel_event],\n",
    "                                              is_blocking = False)\n",
    "        \n",
    "        #since we might as well do something useful while we wait\n",
    "        if(i>0): total += c[i-1].sum()\n",
    "            \n",
    "        #wait for copy-off to finish\n",
    "        copyoff_event.wait()\n",
    "        \n",
    "    total += c[-1].sum()\n",
    "        \n",
    "    return total**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the result\n",
    "1. Checking with out of order execution queues\n",
    "2. Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvidia_oo_norm_local = compute_norm_local(nvidia_oo_queue,\n",
    "                                          a,nvidia_a_buffer,\n",
    "                                          b,nvidia_b_buffer,\n",
    "                                          nvidia_program_local)\n",
    "\n",
    "if(reference_result - nvidia_oo_norm_local > 0):\n",
    "    raise Exception(\"nvidia result does not match!\")\n",
    "    \n",
    "intel_oo_norm_local = compute_norm_local(intel_oo_queue,\n",
    "                                         a,intel_a_buffer,\n",
    "                                         b,intel_b_buffer,\n",
    "                                         intel_program_local)\n",
    "\n",
    "if(reference_result - intel_oo_norm_local > 0): raise Exception(\"intel result does not match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 compute_norm_local(nvidia_oo_queue,a,nvidia_a_buffer,b,nvidia_b_buffer,nvidia_program_local)\n",
    "%timeit -n 10 compute_norm_local(intel_oo_queue,a,intel_a_buffer,b,intel_b_buffer,intel_program_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Challenge\n",
    "* Perform matrix multiplication using global, local and constant memory. \n",
    "* Measure the performance difference between the three.\n",
    "\n",
    "*Hint: Take advantage of multiple indices.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting up memory\n",
    "M = 1024\n",
    "N = 8192\n",
    "dt = numpy.float32\n",
    "dt_size = numpy.dtype(dt).itemsize\n",
    "a = numpy.random.random(size=(M,N)).astype(dt)\n",
    "b = numpy.asfortranarray(numpy.random.random(size=(N,M)).astype(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_source = \"\"\"\n",
    "#define ROWS %d\n",
    "#define COLS %d\n",
    "\n",
    "kernel void opencl_dot(global float *a,\n",
    "                       global float *b,\n",
    "                       global float *c)\n",
    "{\n",
    "    int row = get_global_id(0);\n",
    "    int col = get_global_id(1);\n",
    "\n",
    "    int a_offset = row*COLS;\n",
    "    int b_offset = col*COLS;\n",
    "\n",
    "    float sum = 0;\n",
    "    for(int i=0;i<COLS;++i) sum += a[a_offset+i] * b[b_offset+i];\n",
    "\n",
    "    int c_index = row*ROWS + col;\n",
    "    c[c_index] = sum;\n",
    "}\n",
    "\"\"\"%(M,N)\n",
    "nvidia_program_source,intel_program_source = [pyopencl.Program(context,program_source) \n",
    "                                              for context \n",
    "                                              in (nvidia_context,intel_context)]\n",
    "nvidia_program,intel_program = [program.build()\n",
    "                                for program\n",
    "                                in (nvidia_program_source,intel_program_source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating buffers\n",
    "nvidia_a_buffer,nvidia_b_buffer = create_buffers(nvidia_context,M*N*dt_size,M*N*dt_size)\n",
    "intel_a_buffer,intel_b_buffer = create_buffers(intel_context,M*N*dt_size,M*N*dt_size)\n",
    "\n",
    "nvidia_c_buffer = pyopencl.Buffer(nvidia_context,\n",
    "                           flags=pyopencl.mem_flags.WRITE_ONLY, \n",
    "                           size=M*M*dt_size)\n",
    "intel_c_buffer = pyopencl.Buffer(intel_context,\n",
    "                           flags=pyopencl.mem_flags.WRITE_ONLY, \n",
    "                           size=M*M*dt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opencl_dot(queue,a,a_buffer,b,b_buffer,program,c_buffer):\n",
    "    \n",
    "    #copying data onto device\n",
    "    copyon_events = []\n",
    "        \n",
    "    copyon_events += [pyopencl.enqueue_copy(queue,\n",
    "                                            src=a,\n",
    "                                            dest=a_buffer,\n",
    "                                            is_blocking = False)]\n",
    "    copyon_events += [pyopencl.enqueue_copy(queue,\n",
    "                                            src=b.T,\n",
    "                                            dest=b_buffer,\n",
    "                                            is_blocking = False)]\n",
    "        \n",
    "    #running program\n",
    "    kernel_event = program.opencl_dot(queue,\n",
    "                                      (M,M), #global size\n",
    "                                      None, #local size\n",
    "                                      a_buffer,b_buffer,c_buffer,\n",
    "                                      wait_for = copyon_events)\n",
    "        \n",
    "        \n",
    "    #copying data off device\n",
    "    c = numpy.empty((M,M),dtype=dt)\n",
    "    copyoff_event = pyopencl.enqueue_copy(queue,\n",
    "                                          src = c_buffer,\n",
    "                                          dest = c,\n",
    "                                          wait_for = [kernel_event]).wait()\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvidia_io_queue = pyopencl.CommandQueue(nvidia_context)\n",
    "nvidia_result = opencl_dot(nvidia_io_queue,a,nvidia_a_buffer,b,nvidia_b_buffer,nvidia_program,nvidia_c_buffer)\n",
    "%timeit opencl_dot(nvidia_io_queue,a,nvidia_a_buffer,b,nvidia_b_buffer,nvidia_program,nvidia_c_buffer)\n",
    "nvidia_io_queue.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intel_io_queue = pyopencl.CommandQueue(intel_context)\n",
    "intel_result = opencl_dot(intel_io_queue,a,intel_a_buffer,b,intel_b_buffer,intel_program,intel_c_buffer)\n",
    "%timeit opencl_dot(intel_io_queue,a,intel_a_buffer,b,intel_b_buffer,intel_program,intel_c_buffer)\n",
    "intel_io_queue.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
